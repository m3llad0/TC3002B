This paper presents a method for providing explainability in the integration of artificial intelligence (AI) and data mining techniques when dealing with meteorological prediction. Explainable artificial intelligence (XAI) refers to the transparency of AI systems in providing explanations for their predictions and decision-making processes, and contribute to improve prediction accuracy and enhance trust in AI systems. The focus of this paper relies on the interpretability challenges in ordinal classification problems within weather forecasting. Ordinal classification involves predicting weather phenomena with ordered classes, such as temperature ranges, wind speed, precipitation levels, and others. To address this challenge, a novel and general explicable forecasting framework, that combines inductive rules and fuzzy logic, is proposed in this work. Inductive rules, derived from historical weather data, provide a logical and interpretable basis for forecasting; while fuzzy logic handles the uncertainty and imprecision in the weather data. The system predicts a set of probabilities that the incoming sample belongs to each considered class. Moreover, it allows the expert decision-making process to be strengthened by relying on the transparency and physical explainability of the model, and not only on the output of a black-box algorithm. The proposed framework is evaluated using two real-world weather databases related to wind speed and low-visibility events due to fog. The results are compared to both ML classifiers and specific methods for ordinal classification problems, achieving very competitive results in terms of ordinal performance metrics while offering a higher level of explainability and transparency compared to existing approaches.